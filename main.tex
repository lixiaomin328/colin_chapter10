\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb} 

\title{chapter10}
\author{Xiaomin Li}
\date{March 2021}

\begin{document}

\maketitle
\section{Theoretical neuroeconomics}
\begin{itemize}
	\item 	Self-control
		Fudenberg, benhabib, brocas
	\item Memory and “time travel”
		brocas
	\item States and cues
		Laibson bernheim rangel 
	\item Individual differences: ASD and ADHD
		Landry  mention Haunshofer
\end{itemize}



\section{Low-hanging fruit}
\begin{itemize}
	\item a.	Advertising etc. What part of neuroscience is necessary,, and why? 
	\item b.	Addiction What part of neuroscience is necessary,, and why?  Because of homeostasis and biological system, link to reward system, etc. 
\item c.	Emotion and psych game theory . What part of neuroscience is necessary,, and why? 
\item  d.	Emotion and skills in labor markets. What part of neuroscience is necessary,, and why? 
\item e.	Incommensurability, repugnance etc 
\item f.	Mens rea (Vilares et al PNAS, Jones et al Mens Rea paper). Neuroscience is necessary because self-reports are likely to be biased or unreliable. It is the best way to decode state of mind. 
\item g.	Changing behavior through changing brain activity  write a  section for Chapter 10 about causality. Ballesta OFC results.  Lusha Zhu sleep results.  Ming Hsu, Benedetto lesion results.  Figner? Tms and impatience results.  Simpler results from instruction (Nikki Sullivan?)
\end{itemize}
\section{What’s next?} 
$labor market autism  attention_advantage_ofautism_Neuropsych_Lavie.pdf$  (better performance on inattential blindness and no degradation from cognitive load) – lady cop in The Bridge. Tv show sweden
This concluding chapter has two purposes. The first purpose to describe several analyses which illustrate theoretical neuroeconomics. These technical descriptions first appear here, rather than in previous chapters, because of my belief that is better to hear all about the brain first then use that knowledge to both judge and appreciate the modelling, rather than the other way around.  
The second purpose of this concluding chapter is to sketch some important topics in social science which are most likely to benefit from neuroscientific constructs, facts, and methods. For some of these a natural next step is creating neuroeconomic theory, using the models in the first part of the chapter as exemplars. This section is like  a grant proposal.  

\section{Theoretical neureconomics}
Theoretical neureconomics is the creation of mathematical theories of choice which are inspired by neuroscientific facts. This is an unusual enterprise. In most areas of economic theory, the foundations of a new theory are inherited from previous theories and use the same modelling conventions and style. Decision theories often take the form of systems of axioms which are shown to uniquely imply a particular behavior or functional form describing behavior. The functional form describes behavior if and only if the behavior satisfies those axioms. Such axioms are not justified as biological principles, with some rare exceptions. \footnote{The axiomatic treatment of reward prediction error in Rutledge et al CHECK, and evidence in the form of axiom testing, is one such rare exception. We discussed that in Chapter 2.}
Theoretical neuroeconomics should be judged by different standards, in my opinion. Intuitive plausibility of axioms is not enough. Instead, good neuroeconomic theory should have two “must have” features:
\begin{itemize}
	\item 1.	A good theory should make falsifiable predictions that can be tested by biological data and are particularly interesting as claims about neural processes. 
\item 2.	A good theory should be fruitful and improvable, in sense that other scientists can read and understand it in order to create generalizations or add different features with plausible added predictability. 
\end{itemize} 
Besides those features, there are some “would be nice to have” features of theory too. For example, a theory that makes predictions across species, or across the human life cycle of ontogeny, is especially useful. Such theories expand the set of available and collectible data to test theory.
In addition, many theories have the desirable property that conventional rational choice is nested inside the theory as a special case, when one or more parameters take on specific values. An example is the neural autopilot theory of habit from chapter 2: When the reward reliability threshold $\sigma$ (below which habit-mode is engaged) is zero, the model collapses to conventional rational choice. As has been so successful in behavioral economics (Rabin AER P\&P), this type of parametric nestedness means that every parameter measurement is a test of the relative strength of conventional and neuroeconomic explanations. 
It’s even better if the theory can be constrained so it is easily comparable to alternative behavioral theories (as in the Benhabib and Bisin (2005) endogeneous-control model of consumption and savings). It’s also useful if the theory has a natural causal interpretation, since there are many methods for direct causal influence on brain regions, especially for non-human animals. 
And finally, it is not necessary, but is potentially useful, if a neuroeconomic theory can say something about human welfare. In plain language, consumer welfare what is best for consumers as they themselves would judge it. A welfare analysis allows us to analyze whether proposed policies are good or bad, for welfare thus defined. This is a messy topic, even for behavioral economics, and is no less messy for neuroeconomics. The scientists who have thought hardest about the welfare consequences of different behavioral theories do not always agree. Welfare judgments based on neuroeconomics will be harder still. 
We touched on the topic of welfare in the chapter 2 discussion of “wanting” and “liking”. Liking should be the welfare criterion. Decoupling of wanting and liking therefore implies that people are not always wanting-- and choosing-- what is best for them. That implies there is room for improvement in their own choices (as judged by their own liking, not by a bureaucrat, religious figure, parent, psychiatrist, advice columnist, or Twitter user). Whether a neuroeconomic theory can generate interesting welfare analyses and defensible policies remains to be seen. It is not a major goal of our enterprise. 
Cowen paper ??
\section{Neuroeconomic theory} 
\subsection{Self-control}
Fudenberg and Levine (AER 2006) 
Fudenberg and Levine (2006) present a dual-self model of impulse control. A long-run self (LR) makes decisions which can constrain the series of  decisions of myopic  short-run selves ($S_t$). The constraints create a self-control cost. The long-run self’s utility is the discounted sum of the short-run utilities minus self-control costs. 
It is a simple and appealing approach. I think of it as metaphorically as describing a parent and the behavior of a child who is myopic. 

Here are the moving parts, for the special case of consumption-savings decisions: $y$ is a state variable (such as income); $a$ is the savings action by a self $S_t$; ($1-a$ is consumption); and $r$ is a self-control action chosen by the LR-self. In the savings example, income in period t+1 is $y_{t+1}=Ra_ty_t$ where R is the rate of return on savings and $a_t$ is the percentage of money saved. (Consumption everything and saving nothing is $a_t=0$.) 
The S sel(ves) in general have myopic utility $u(y,r,a)$ The “base” or unconstrained preference of the S-self is given by 
\[
u(y,0,a) = log((1-a)y)
\]

This utility is decreasing in $a$; left to his own devices, the myopic self would spend everything by choosing $a=0$. This is not good from the point of view of the LR-self, because it reduces future income because $y_{t+1}=Ra_ty_t$.
Some precursor assumptions imply a cost of self-control which is a linear multiple of the difference between the S-self utility from consuming nothing and the base preference, as follows:
\begin{equation}
	\begin{split}		
	C(y,a) &= \gamma (log(y)-log(1-a)y)\\
	&=-\gamma log(1-a)
\end{split}
\end{equation}

For a special case of constant relative risk-aversion  (CRRA) utility, there is a unique solution to the LR-self’s optimization problem, which is a constant savings rate $a$. This reduces the LR-self’s reduced form utility (implicitly controlling for choices of self-control $r$) of  

\[ U_{RF} = \frac{(1+\gamma)log(1-a)+log(y_1)}{1-\delta} +\frac{\delta log(Ra)}{(1-\delta)^2}
\]
Recall that the LR-self can choose a constraining value of $a^*$ which the $S_t$ selves will be constrained to obey. Differentiating the $U_{RF}$ with respect to $a$ gives the first-order condition 
\[\frac{\delta}{1+\gamma-\delta*\gamma}\]

The constrained $a^*$ that maximizes LR-self utility is decreasing in $\lambda$, showing that more costly self-control leads to less constraint on S-self saving. Less obviously, it is also increasing in the discount factor $\delta$, so that a more patient LR-self allows more S-self consumption. 
The rest of their analysis is applied to special cases of liquidity, involving cash-on-hand from an ATM (which the S-self will spend right away, if unconstrained) versus illiquid cash receipts. There are also technically interesting comparisons between beta-delta discxounting results and temptation preference specifications which build in a distaste for bigger choice sets that create temptation (Gul and Pesendorfer, Dekel GET CITES FRM PAPER)

\begin{quote}
	“But as economists, our primary goal is a 
model that fits reasonably well, and is simple enough to 
apply in a range of economic situations. Consistency with 
what is known about brain function is a plus, as it gives 
more reason to be confident about the model's predictions, 
but this is not our primary objective. P 1471
\end{quote}
The usual arguments and evidence for independence of irrelevant alternatives and the independence axiom are not compelling when an intermediate 
decision such as self-control is involved. More generally, once one leaves the domain of the 
standard model, where the assumptions on behavior have some normative appeal, it becomes more difficult to evaluate axioms on a priori 
grounds. In this situation, insights from psychology and neuroscience, such as the presence of multiple systems within the brain that respond differentially to the timing of rewards, can be particularly useful in suggesting useful assumptions.


These cognitive activities can, however, be sensibly regarded as as- 
pects of the long-run self, while it makes sense to model the expectations of the short-run self as arising from a process of stimulus-response 
learning that depends solely on history, and does not involve forward-looking expectations. 
We would then theorize, based on introspection 
and casual empiricism, that the long-run self can train the short-run self by manipulating this 
stimulus-response learning. This leads to the 
possibility of the deliberate formation of "habits" with a view toward lessening the cost of self-control



Glimcher, 1999.) But as economists, our primary goal is a model that fits reasonably well, and is simple enough to
apply in a range of economic situations. Consistency with
what is known about brain function is a plus, as it gives more reason to be confident about the model's predictions,
but this is not our primary objective.
Glimcher, 1999.) But as economists. our primary goal is a model that fits reasonably well, and is simple enough to
apply in a range of economic situations. Consistency with
what is known about brain function is a plus, as it gives
ore reason to be confident about the model's predictions,
t this is not our primary objective.
idea that self-control is a limited resource. The usual arguments and evidence for independence
of irrelevant alternatives and the independence axiom are not compelling when an intermediate
decision such as self-control is involved. More generally, once one leaves the domain of the
standard model. where the assumptions on behavior have some normative appeal, it becomes more difficult to evaluate axioms on a priori grounds. In this situation, insights from psy-
chology and neuroscience, such as the presence Of multiple systems within the brain that respond differentially to the timing of reward can be particularly useful in suggesting useful
assumptions. We have chosen what we feel is the most straightforward way to capture these insights, namely to cast them as assumptions on the implicit preferences of the various systems
or selves. This is simple and direct but, unlike
                
Our resolution of the Rabin paradox shows how the dual-self model can capture some sorts Of context effects, as the model makes different
predictions about the response to unanticipated payments, depending on whether they are received on the floor of a casino or the lobby of a
ank. Cues are Obviously the key to understanding the effect Of context in general, and framing in particular. The dual-self theory implies that it
is the attention span of the short-run self that is reltesa Sitermimn w
most difficult melinrssue in confronting these types of issues. This
suggests that one might be able to use experimental and physiological data to determine the relevant contexts and frames. The dual-self theory would then enable us to paste information
about the motivation of the myopic self into the broader context in which real decision-making takes place.
Instead of following the expectations-based approach, we would like to model the long-run
self having "taught" the short-run self to attach positive affective weight to certain variables that have long-run consequences, as in the learning Of cues. Here the use of stimulus-
response models of learning may play an important role. The standard forms Of these models seem to be a poor fit for many aspects of human cognition. For example, faced with no
observations, people will respond differently depending on their prior knowledge of a situation. More strikingly, we know that people
can learn by "figuring things out" without any external stimulus at all. These cognitive activi-
ties can, however, be sensibly regarded as aspects of the long-run self, while it makes sense to model the expectations of the short-run self
as arising from a process of stimulus-response
learning that depends solely on history, and does not involve forward-looking expectations.
We would then theorize, based on introspection and casual empiricism, that the long-run self can train the short-run self by manipulating this
stimulus-response learning. This leads to the possibility of the deliberate formation of "habits" with a view toward lessening the cost Of
                
How does self-control work mechanistically?  FL do not know but their thoughts are interesting, especially for 2006. FINISH LATER 

This fork in the modelling road, between naivete and sophistication in vmPFC encoding of the message from dlPFC, is familiar in social science theory but is not common in the same way in theoretical neuroscience.  It gives one pause. Is it plausible that one brain region would be ignorant of health value $h$ (yes, that’s highly plausible), receive input from another better-informed region (also highly plausible), and then form an inference about what a specific non-input means about a hidden numerical value (hmmm). 
This is a good simple example of the crux move required for theoretical neuroeconomics to climb higher.  An important question for behavioral and neural prediction is whether the vmpFC can be uninformed about abstract input about unhealth $h$ but also contain the neural capacity to infer what “no $h$ value” might imply. No current data gives us a clear answer to this question. 

Keep in mind that in other brain circuits, the idea that a computation like $E[h|no modulation]$ can be done is perfectly reasonable. Reward prediction error is an example: It encodes a prediction and a surprise. vmPFC would just have to include—or be circuit-connected to—a history of $h$ values and modulations that can be computed what a non-modulated $h$ is likely to be, numerically. 
More optimistically, once the computational pieces are laid out in mathematics, one can easily imagine how to design experiments to separate where different numbers are encoded. There is every reason to be optimistic that several papers tackling this question would establish whether this analytic framework is actually implemented in the brain, and if so (it probably is) where the implementation occurs. 

Now let’s get back to the analytical story. The analysis has two stages like a sequential game. We’ll first figure out the second step-- what the vmPFC will choose depending on what information about $h$ is received. The vmPFC will decide to choose the food if
\[
\theta>\theta^{S} \equiv \alpha h
\]
when there is modulation. 
If there is no modulation then the decision will depend on whether inference is naïve (Nf) or sophisticated (Ns). If the inference is naïve then the decision is to choose the food if 
\begin{equation*}
	\theta>\theta^{N f} \equiv 0
	\end{equation*}
(where $\theta_{Nf}=0$)
If the inference is sophisticated the food choices is made if 
\begin{equation*}
	\theta>\theta^{N s} \equiv \alpha E[h \mid h \in H]
	\end{equation*}

(where H denotes the set of h values for which no modulation is done).

Next comes the first step, which is what modulation choice is made by dlPFC given what it expects the vmPFC to do with the input dlPFC sends.
Finish later after Latex translation  
Modulation choice (by dlPFC):
\begin{equation*}
	V^{S}(h)=\int_{\theta^{S}}^{1}(\theta-\alpha h) d \theta-c
	\end{equation*}
Value of Modulation:  
\begin{equation*}
	V^{N f}(h)=\int_{\theta^{N}}^{1}(\theta-\alpha h) d \theta
	\end{equation*}
Value of no Modulation: 
Choice:
\begin{equation}
	\begin{aligned}
	V^{S}(h)>V^{N f}(h) & \Leftrightarrow \Delta^{N f}(h) \equiv \int_{0}^{\alpha h}(\alpha h-\theta) d \theta>c \\
	& \Leftrightarrow h>\eta(c, \alpha) \equiv \sqrt{2 c} / \alpha
	\end{aligned}
	\end{equation}
	This inequality is a nice simple expression. It says that modulation will occur (assuming the vmPFC sophisticatedly understands what a non-message implies) if the unhealth value is sufficiently high $h>sqrt{2}{2c}/\alpha$. A larger cost $c$ raises the bad-health threshold for reporting and a higher health weight $\alpha$ lowers the threshold. 

	Now we can show some results. Fix values of $c, \alpha, f(h)$. In the naïve case, there is  a unique equilibrium for the modulation choice by dlPFC, in which only messages about high unhealth values $h$ are sent when $h>sqrt{2}{2c}/\alpha$. The intuition is straightforward: The vmPFC will assume $h=0$ unless modulation occurs. Given the self-control cost $c$, it only pays to send information about highly unhealthy foods.  Picture a parent talking on the phone while their child is picking out a snack at the Manhattan Beach food stand. Diverting attention from the phone is the self-control cost. The parent only bothers to turn from the phone and admonish the child if he is about to choose something really unhealthy (perhaps Slim Jims).
The sophisticated case is more technically and behaviorally interesting. 
First consider the case where the unhealth distribution f(h) has many low values—that is, most goods are not too unhealthy. Then the optimal modulation is to only warn against the high-$h$ unhealthy goods with $h>h^{**}$, as shown in Figure ?. The horizontal line in the lower left separates high values of taste for which the food is consumed, because the decision value $\theta - \alpha E[h|h<h**]$ is positive, from lower values of taste for which the food isn’t consumed. The diagonal line on the right, where $h>h^{**}$ on the x-axis, is where the value of $h$ is modulated so consumption depends on $\theta-\alpha*h$. 

FIGURE Environment 1
The case above is where f(h) has many low values. What if f(h) is a choice set full of unhealthy junk food? Then the equilibrium prediction flips around, as seen in Figure ?. In this case, the dlPFC transmits the lowest h values to vmPFC and gives up at the higher unhealth level $h^*$. This is like the parent a children’s birthday party who tries to force a few carrot sticks on their little one (“With Ranch dressing, your favorite!”), then gives up as little Skylar makes a beeline toward the chocolate tower and cotton candy. 

Notice that there is a discontinuity at $h=h^{**}$ in Figure ? (and at $h^*$ in Figure?) . These kind of jumps are common in these threshold models. As an experimenter, it is thrilling to see because it suggests that sampling around $h^{**}$ can really stress-test a bold prediction from the math. The value of $h^{**}$ depends on the modulation cost $c$, which depends on unhealthy penalty weight $\alpha$, that might be estimated behaviorally from choices, and on f(h), which can be controlled by the experimenter.  

FL could apply to time and has been applied to explain choice under risk evidence (Levine, Fudenberg, Maniadis ?)

An approximate dual-self model and paradoxes of choice under risk
D Levine, D Fudenberg, Z Maniadis
Journal of Economic Psychology

Benabou and Pycia (2002) is an elegant simple paper which connects decision theory about temptation-influenced choice to hypotheses about “neural lobbying”. Their starting point is Gul and Pesendorfer () well-known theory of temptation. They describe a two-stage choice in which a choice set (or “menu”) A is first chosen, then an element x of A is chosen in the second stage. At the first-stage the decision maker correctly anticipates what she will choose in the second stage. 

The novelty in their approach is that axioms over menus A, B satisfy set-betweenness
\begin{equation*}
	A \geqslant B \text { implies } A \geqslant A \cup B \geqslant B
\end{equation*}
Normally, of course, in conventional modelling more choice is assumed to be preferred to less,  so the larger choice set A U B is always (weakly) preferred. This alternative axiom allows for the possibility that $A>A \cup B>B$.

Their interpretation is that B will not be chosen in the second stage, but it creates temptatiom or conflict so that its existence makes the menu A U B worse, in the first stage, than choosing A. 

They show that set-betweenness, along with utterly conventional axioms, implies that the following utility over menus $U(A)$ represents preferences.
\begin{equation*}
	U(A) \equiv \max _{x \in A}(u(x)+v(x))-\max _{y \in A} v(y)
\end{equation*}

This is a crisp decomposition of basic preference u(x)  (which is how people would choose in the absence of temptation) and a second index v(x).  If x is most appealing, but y is most tempting, then $u(x)>u(y)$ but $v(x)>v(y)$.  Removing y from the choice set therefore increases first-stage utility from $u(x|A)= u(x)+v(x)-v(y)<u(x)$  to $u(x|A={x})=u(x)+v(x)-v(x)=u(x)$. 

Benabou and Pycia’s contribution has two steps. They first suppose that if the larger set A is available in the second stage, it is plausible that there is an internal conflict between x and y, and the agent chooses x and y with probabilities. 

\begin{equation*}
	\text { the agent chooses } \tilde{x}=\left\{\begin{array}{ll}
	x \text { with probability } p_{x} \equiv \frac{u(x)+v(x)-u(y)-v(y)}{u(x)-u(y)} \\
	y \text { with probability } p_{y} \equiv \frac{v(y)-v(x)}{u(x)-u(y)}
	\end{array}\right.
\end{equation*}

With a little algebra it is easy to show that the expected utility of this choice conflict, at stage 1, leads to the same valuation $U(A)$ as above. The mathematics is exactly the same, but now the interpretation is that the stage-1 chooser fears succumbing to temptation and choosing the infer y if she chooses menu A and proceeds to stage 2. 

Next they introduce the concept of a Doer and a Planner fighting for control in stage 2 (as in Shefrin and Thaler, 1981, and similar in spirit to Fudenberg and Levine’s dual self approach). The Doer has utility for based on v(x), and the Planner has utility based on u(x)+v(x).  The two ‘selves’ have mental resources $r_D$ and $r_P$. They engage in a kind of mental lobbying which results in the probabilities $p_y =\frac{r_D}{r_D+ r_P}$ and $p_x=\frac{r_P}{r_D+ r_P}$ This can be modelled as a game between two players simultaneously choosing of $r_D+ r_P$, a cost which is subtracted from utility payoffs.

The Nash equilibrium results in resource choices

\begin{equation*}
	\begin{array}{l}
	r_{P}=\frac{\left(r_{D}+r_{P}\right)^{2}}{v(y)-v(x)} \\
	r_{D}=\frac{\left(r_{D}+r_{P}\right)^{2}}{(u+v)(x)-(u+v)(y)}
	\end{array}
\end{equation*}

These values imply the same probabilities $p_x, p_y$ as in the internal lottery representation. 
Thus, in the first stage the evaluation of menu A can be interpreted as rational anticipation of an internal neural battle between one region which encodes (and “prefers” to maximize) $v(x)$, and another region which encodes $u(x)+v(x)$.
This interpretation invites a neural iinterpretation. They suggest resources could be “nervous impulses, energy, Freudian ‘libido’, etc.”.  
After reading this book you should have a clearer idea, and perhaps even a recipe for how direct brain measurement could test this theory.  For example, recall the evidence from Hare et al, in which we think of tempting food taste as represented in vmPFC (Doer-land) and health information is supplied by a Planner to implement the choice based on $u(x)+v(x)$. 

How to test with both choice data.

Automatic and controlled processes in consumption and savings

Benhabib and Bisin (2005) is an early neuroeconomic theory model about neurally-inspired self-control in a simple dynamic consumption-savings model. Their starting point is the distinction between automatic and controlled processing. They use the canonical Stroop task as an illustration. 
In each period agents must choose a consumption level $c_t$. A discount rate $\delta$ is applied to future costs and benefits.\footnote{Note that their notation uses $\beta$ but our discussion will substitute the more conventional $\delta$} [XIAOMIN CHANGE FROM BETA IN THEIR ORIGINAL SETUP].  The building block decision at time $\tau$ for future periods t and t+1 is the structure familiar to economists, 

\begin{equation*}
	\begin{array}{l}
	\max _{c_{t}, c_{t+1}} \beta^{t}\left[U\left(c_{t}\right)+\beta U\left(c_{t+1}\right)\right] \\
	\text { s.t. } \quad c_{t}+c_{t+1} \leqslant w
	\end{array}
\end{equation*}

As discussed at length in chapter TIME?, in these choices there are often impatient reversals in which a value $c_t^*$ is planned at time $\tau<t$, but when the once-future time t arrives people act more impatiently and suddenly prefer $c_t>c_t^*$. They postulate that internal commitment which ‘enforces’ $c^t*$ comes from mechanisms which operate as [costly] cognitive control. 

The general model is a partial equilibrium dynamic economy with discrete time periods $t \in {0, 1, \infty}$. Wealth $k_t$ accumulates according to $k_{t+1}=a_tk_t-c_t$ where $a_t$ is a (stochastic) period-specific return on wealth.\footnote{As is common in this type of modelling, because the framework is so general it is only easily solved by placing strong restrictions on the moving parts. For example, $a_t$ is assumed to be i.i.d and strictly positive, and have a well-defined mean $E(a)>0$. We’ll skip most of these details unless they are crucial to generating intuitive interpretation.}

At time t there is an observable i.i.d. “temptation” $z_t \in [1,\infty)$ with mean $E(z)>1$. The temptation inflates the immediate utility of consumption, creating $U(z_tc)$. The CRRA/CES utility $U(c)=\frac{c^{1-\sigma}} {1-\sigma }$ is assumed; $sigma<1$ corresponds to concave utility (=diminishing marginal utility) and lower $\sigma$ corresponds to more concavity. Consumption is assumed to be a linear period-specific multiple of available wealth, $c_t=\lambda_ta_tk_t$. This assumption allows us to focus attention on the “propensity to consume” $\lambda_t$. 
The first order of business is to formally derive the consumption-saving rule which explains what $\lambda_t$ is at time t. It will be the combined outcome of an automatic consumption process $\lambda^I_t$ (where $I$ stands for impulsive) and potential override by “a ‘supervisory attention system’ governed by expected rewards”.\footnote{While I apologize for sounding too nitpicking, this is a nice tiny example of how good \emph{lingua franca} pidgin science languages starts and can be iteratively improved. The authors use the phrase “supervisory attention system” from cognitive neuroscience. For me—and I hope for many of you—it is thrilling and remarkable that these outstanding economic theorists are drawing inspiration from neuroscience, which is a field far outside theirs. In the model, however, there is no special process that corresponds precisely to attention, per se. As neuroeconomics progresses,  it is fair to ask how exactly attention could be best included in the model, which creates an opportunity to measure attention and choice jointly and test the model in a more demanding way. As we will see, there is an hypothesized cost $b(a,k)=b(a_tk_t)^{1-\sigma}$ to controlling (or overriding) the automatic system. This cost can be considered a reduced-form (or “black box”) way of including costly attention. As we will also see, they do also study the case in which there is cognitive load so that $b(a,k$ increases exogeneously. This is again a way to study attention change indirectly.} If it kicks in, the controlled system is assumed to choose the value of $\lambda_t$ which maximized the current consumption utility and the (discounted) expected continuation value D(.) which is a function of possible values of wealth return $a_{t+1}$ and temptation $z_{t+1}$. This is written as 

\begin{equation*}
	\lambda^{\alpha}=\arg \max _{\lambda} U\left(\lambda a_{t} k_{t}\right)+\beta E\left[D\left(a_{t+1},(1-\lambda) a_{t} k_{t}, z_{t+1}\right)\right]
\end{equation*}

It is notable that this maximization step also assumes “rational expectations” about future\footnote{The reason is that maximization only looks one step ahead, to D(.) as a function of $a_{t+1}$ and $z_{t+1}$, is because that D(.) function includes anticipation about future periods too. That is, the corresponding maximization equation for $\lambda_{t+1}$ will include $D(.)$ that is a function of $a_{t+2}$ and $z_{t+2}$. This is called dynamic programming. It originated in the applied mathematics of operations research but later became, among other uses, a powerful tool for deriving results in dynamic economic systems like these.} choices (built into the expectation term). This assumption is second-nature in modern economic theory and is responsible for some of the interesting predictions. For example, the control system is assumed to understand that in the future there will be a distribution of possible returns $a_{t+1}$ and temptations $z_{t+1}$, and plans accordingly. 
Sidebar: As is often true in economic theory, this is a behaviorally unrealistic assumption but its unrealism is tolerated— \emph{for now}—because it enables wizards like Benhabib and Bisin to solve the model and make nonobvious predictions. There is little doubt that these unrealistic assumptions are probably wrong. (Most theorists are well aware of that, too.\footnote{Indeed, in their footnote 30 BB acknowledge that from a neuroeconomic view, the model is incomplete because it does not have a mechanism for generating rationality of expectations. They note that “Correct anticipations could be based on reinforcement learning procedures”. Adding such a procedure could be very useful empirically because it will generate different predictions across the economic lifecycle. A plausible conjecture is that young consumers underestimate the strength of their future automatic responses and set the control threshold $\bar{\lambda}$ too high, but learn to reduce it over time.} But the only criticisms of unrealistic assumptions which deserve clear attention are (in order of scientific value from low to high):  (low) well-established evidence of unrealism; (medium) clear empirical tests showing bad predictions resulting from unrealistic assumptions (“anomalies”); or (high) a model with more realistic assumptions that makes competing predictions. And lest we judge the current control model too harshly, note that it is itself a model of the (high) type-- it is a reaction to simpler models with less neurally realistic assumptions (i.e., with no capacity to control automatic behavior). 
Here is an example of the immediate payoff of such unrealistic assumptions: Under their assumptions, the solution to the controlled system’s maximization is a \emph{constant} $\lambda_E$. This is rather amazing! This controlled policy number is independent of time, wealth, and also how high or low the returns $a_t$ and $z_t$ are in every period. 

Now back to our main story: In general controlled processing will inhibit automatic consumption at time $t$ when the regret from not inhibiting (including future consequences) is greater than the mental cost $b(.)$.  Formally, this looks like inhibiting if the benefit $R(.)$ is above the cost $b(.)$
\begin{equation*}
	\begin{array}{l}
	R\left(a_{t}, k_{t}, z_{t}\right)>b\left(a_{t} k_{t}\right)^{1-\sigma} \\
	\qquad \begin{aligned}
	R\left(a_{t}, k_{t}, z_{t}\right)=&\left[\max _{\lambda} U\left(\lambda a_{t} k_{t}\right)+\beta E\left[D\left(a_{t+1},(1-\lambda) a_{t} k_{t}, z_{t+1}\right)\right]\right] \\
	&-\left[\max _{\lambda \geqslant \lambda_{t}^{I}} U\left(\lambda a_{t} k_{t}\right)+\beta E\left[D\left(a_{t+1},(1-\lambda) a_{t} k_{t}, z_{t+1}\right)\right]\right]
	\end{aligned}
	\end{array}
	\end{equation*}

Solving for the optimal $\lambda_E$ and policy gives the following simple cutoff rule: 
Proposition
2. There exist a $\bar{z}$ such that
$$
\lambda\left(z_{t}\right)=\left\{\begin{array}{ll}
\max \left\{\lambda^{E}, \lambda^{I}\left(z_{t}\right)\right\} & \text { for } z_{t} \leqslant \bar{z} \\
\lambda^{E} & \text { else }
\end{array}\right.
$$

Intuitively, this means that the controlled system always maintains a simple fixed propensity to consume fraction $\lambda_E$, which constrains consumption when temptation $z_t$ is above the threshold $\bar{z}$. When temptation is less than $\bar{z}$, automatic consumption $\lambda^{I(z_t)}$ is sometimes higher. The controlled system tolerates this if ``it does not perturb his underlying consumption-saving plan too much and therefore does not have permanent effects on his prescribed wealth accumulation''(p 471).

Some “comparative statics” then follow. This term refers to statements of the form “If model parameter X is higher than behavioral dependent variable Y is higher”. It is these comparative static predictions which are often the focus of empirical testing (see later discussion about reduce-form vs. structural and neuroscience).
To derive anything strong, $a_t, z_t$ are assumed to be independent.\footnote{Tutorial and homework for budding neuroeconomists: It is common to make strong assumptions—sometimes called ``heroic”—to get strong predictions. There is nothing wrong with that. Independence of $a_t, z_t$ is one such assumption. In this case, the neuroeconomic reaction should be: Are there reasons for why $a_t, z_t$ would $\emph{not}$ be independent? Is there dependence statistically large or small? Is it isolated to particular times, people, or places? Could it depend on technology or institutional details? Can it sometimes be negative and sometimes be positive? If the answer to any of these questions is “large” or “Yes” then we have an empirical opportunity, leverage, or traction to use data. More knowledge of neuroscience enables us to ask the same types of questions about neural processes: What brain properties and evidence would lead us to think a surprising jump in wealth creates more temptation (or vice versa)?} 
When the distribution of $z_t$ shifts higher, overall utility decreases. The control system sets a higher $\lambda^E$) and reduces the cutoff $\bar{\lambda}$. So controlled choice spends more but automatic choice is controlled more often. 
When the control cost function $b(a,k)$ increases, both $\lambda$ and $\bar{\lambda}$ increase.
Comparison to two benchmarks: Because the dynamic savings-consumption framework is familiar in economic theory, it is easy to compare the automatic-controlled predictions with those from two benchmarks: Costless control (b=0, the workhorse lifecycle optimization model); and an interpersonal game approach with $\beta-\delta$ present bias (Laibson, 1996; and recall chapter Time?).
The lifecycle case is easy to solve (it is a special case of a Lemma). It leads to a constant propensity to consume of $\lambda^*$. They show that assuming $\lambda^I(z_t)> \lambda^*$ implies $\lambda^E> \lambda^*$. That is, compared to the costless-control benchmark, costly control always leads to more consumption. This is not an obvious result: It could be, for example, that automatic overconsumption is compensated for by lower-than-optimal consumption $\lambda^E<\lambda^*$ when consumption is controlled. But recall that even when controlling consumption, the agent rationally expects that there will often be automatic overconsumption in the future (at rate $\lambda^I(z_t)$), reducing future wealth; so even when controlling consumption, a little extra $\lambda_E$ does not ruin the overall budgeted plan. In the intrapersonal game, they assume the current agent is tempted by $z_t$ but is not influenced by future temptations (except through their expected influence on future choice). In the Markov Perfect Nash (MPN) equilibrium of the game among successive selves, there is a consumption rule $\lambda^M(z_t)$ depending only on $z_t$ (and increasing in $z_t$). It is larger than the optimal $\lambda^*$. In the special case when the automatic consumption rule $\lambda^I(z_t)$ equals the multiple selves rule consumption $\lambda^M(z_t)$, the controlled consumption $\lambda^E < \lambda^M(z_t) \forall z_t$. The contrast between these two behavioral cases is interesting.  The multiple selves $\lambda^M(z_t)$ is a compromise between wanting to impulsively consume in time $t$ and also wanting to constrain the future self from consuming. The BB endogeneous control at time t is better in the sense that $\lambda^E < \lambda^M(z_t)$. Compared to multiple-selves PMN, the controlling agent can afford to consume less (and save more) because it rationally expects to exert control in the future when it is most needed— at high values of $z_t$ which allow high  $\lambda^M(z_t)$ consumptiom by multiple-selves. 
Empirics: An interesting empirical test of the different models is consumption from windfall gains, such as winning lotteries. Since at least Shefrin and Thaler (1992?) it has been known that marginal propensity to consume (MPC) from windfalls is very high. 
What do these theories say? Since windfalls are unplanned, in rational lifecycle models people should have a low MPC and save a lot.  Both multiple-selves and control models allow high MPC from windfalls. Only the control model suggests that MPC will be lower, in percentage terms, for larger windfalls. Evidence from windfalls indicates MPCs 60-90\%. A beautiful example from restitution payments to Israelis also shows that MPC is lower for very large windfalls, where control is predicted to restrain MPC.   
Another difference in empirical predictions of theories is about illiquid investments (e.g., housing). In the multiple-selves view, illiquidity is a way to constrain future selves; these agents will therefore accept a negative return for such assets. In the endogeneous control theory, high illiquidity has less commitment value because costly control can constrain the worst automatic impulses. Illiquid assets will therefore only be held for a positive return. How could this theory be tested using neural data? BB offer a Figure which illustrates the component processes and timing of activation. Their figure is just a few substantial tweaks away from a workable design.

\section{Memory and “time travel”}
Tulving () FINISH proposed that memory enables humans to mentally “travel” backwards and forwards in time. This capacity is called “mental time travel”. (CFC FINISH READING).  We discussed this topic in Chapter 7? about time preference. There we discussed a surprising fact made evident from neuroscience c 2010,  that memory is involved in the weight put on future rewards through a “prospective memory” planning system.\footnote{Cognitive science offers other computational accounts of the purpose and mechanics of memory e.g. INZ $https://www.sciencedirect.com/science/article/pii/S1364661320303053$}
Brocas and Castillo (2018) create a simple model of how the combination of attention and mental time travel might guide decision making. A canonical example is a person who drives to work and parks their car in a parking lot regularly, but at different locations, presumably due to events out of their control.  The location chosen on a particular day is $x$ is drawn from a distribution X with variance 1/p. 

$$
X \sim \mathcal{N}\left(\theta, \frac{1}{p}\right)
$$

The average location is $\theta$ and $1/p$ is the precision or regularity of locations; note that a high value of $p$ corresponds to a low value of variation in x and hence high memory precision. 

An episodic memory $m$ records the location with a noise parameter $u$, which has precision $1/e$. 

$$
m=x+u \quad \text { where } \quad u \sim \mathcal{N}\left(0, \frac{1}{e}\right)
$$

The value of $e$ is an endogeneous choice variable, corresponding to some scarce mental resource—we’ll call it attention—which improves precision because higher $e$ creates a lower $1/e$ and hence a lower variance of the memory $m$ around the correct location $x$.  
Assume attentional effort has a quadratic cost $c(e)=e^2/2$. The recollected memory $m$ is used to choose an action $a$. The cost of a mistake in choosing $a$ when the true car location is $x$ is assumed to be quadratic, $c(a|x)=-\lambda(a-x)^2$ where $\lambda$ is a parameter that scales the cost of a memory mistake. 
Given a memory $m$, the optimal action maximizes the expected loss function, based on the conditional cdf $F_e(x|m)$ which is the probability distribution of all the x values given a memory m (which depends on the mental effort $e$, which appears in the subscript. This optimized action $a^*(m,e)$ is given by
$$
a^{*}(m, e)=\arg \max _{a}-\int_{x} l(a-x)^{2} d F_{e}(x \mid m)
$$

The optimal action can be expressed as a similar weighted average of the prior location $\theta$ and the memory $m$. The weights are the relative precisions (recall that a high value of precisions $p$ and $e$ lowers variability, and increases the confidence weights on the prior and memory. That weighted average is
$$
a^{*}(m, e)=\frac{p}{e+p} \theta+\frac{e}{e+p} m
$$

Given the optimal actions that result from mental effort $e$ and the associated memory distribution, we can work backward to determine the values that results from the optimal effort $e$, which will depend on the location. This $V_x(e)$ is given by

$$
\begin{aligned}
V_{x}(e) &=-\int_{m} l\left(a^{*}(m, e)-x\right)^{2} d G_{e}(m \mid x)-\frac{e^{2}}{2} \\
&=-l\left(\frac{e+p^{2}(x-\theta)^{2}}{(e+p)^{2}}\right)-\frac{e^{2}}{2}
\end{aligned}
$$

The solution is easy to see graphically in Figure ?  There is a range of locations $x \in {\bar{x},\underline{x}}$  in which attention/effort e*(x)=0, because $x$ is close enough to the prior mean $\theta$. The likely cost of being wrong is low compared to the $e^2/2$ cost of trying to find out more. 
There are also two symmetric functions in which guesses about $x$, if they are outside the ${\bar{x},\underline{x}}$  dead zone, lead to values of $e(x)$ which are strongly increasing for extreme $x$. The brain is using costly resources to remember these unusual values of $x$ because it is a large mistake to forget. 
Fig. ?(b) shows the value of the expected actions as  function of the underlying action $x$. The largest gap is around x\%. 

This is a nice clean prediction about where memories will be accurate or inaccurate. 
FINISH

MTT develops as soon as children understand the concept
of yesterday" and tomorrow," and in conjunction with the development of episodic
memory (Hayne and Imuta, 2011; Suddendorf and Busby, 2005). The MTT ability is also
less developed in subjects with a poor visual imaginary or those who tend to suppress
emotions (D'Argembeau and Van der Linden, 2006).
(Hayne and Imuta, 2011; Suddendorf and Busby, 2005).

(D'Argembeau and Van der Linden, 2006).  FINISH READ
\section{States and cues}

\section{Individual differences}
Landry (2020) is a theoretical neuroeconomics analysis of individual differences based on two common disorders-- autism spectrum disorder (ASD) and Attention-deficit/hyperactivity disorder (ADHD). There is no better analysis illustrating the potential of combining economic theory, and assumptions based on neuroscience, to produce surprising clear predictions. It is a tour de force. 
In terms of our Chapter 1 introductory discussion, this is a beautiful illustration of how neuroeconomics can help us understand individual differences. The target individual differences are not those which non-clinical social scientists typically prioritize (such as age, gender, education, and income). Instead, these individual differences emerge from clinical evidence and neuroscience. They are of first-order “economic” importance because they are not uncommon, and they both impact education, labor markets and worker productivity (not to mention everyday mental health and well-being of people and their families). 

This paper is an example of computational psychiatry. The approach is to hypothesize a parameter that influences behavior, for which extreme or abnormal parameter values seem to correspond to disorders. The key step is then to describe a decision problem, derive predicted behavior mathematically for different parameter values, and show testable implications.  

The generic decision problem is about attention switching between tasks. The problem has two steps. First, a cue arrives with salience $\sigma$ indicating a new task to which the agent can switch. The agent decides— almost surely implicitly—whether to attend to the cue at all. Second, if the cue is attended to, the expected reward value of the new task opportunity, $\phi(\sigma)$,  is revealed. The agent then decides whether to switch to the new task or not. The first decision step is whether to attend to the cue, and the second decision step is whether to switch to the new task.

The key variable is a value $\lambda \in [-1,1]$ called “diversion bias”. This is a reward-scaled value which indicates a preference for not diverting attention or switching ($\lambda<0$), or a preference to attend and switch ($\lambda>0$).\footnote{Many social scientists would call this a “preference”, utility, or source of value. However “bias” is the term often used in cognitive neuroscience for this type of predisposition so we’ll use that term, as Landry does.}

An empirical argument is made that $\lambda$ is associated with synaptic conductance and tonic dopamine (DA), and with ASD ($\lambda<0$) and ADHD ($\lambda>0$). The arguments are summarized in Table ?. This is the closest link yet proposed, to my knowledge between a specific parameter in theoretical neuroeconomics and a neurobiological process. 

The neural evidence is summarized in Table ?.  

For precision, the agent is assumed to trade off costs and benefits and make optimal attention and task-switching choices, given implicit knowledge of all the parameters and functions. As is typical in economics, the first-stage attention allocation is based on anticipated second-stage task-switching behavior. This is a strong assumption, behaviorally, but leads to clear predictions. As noted in our discussion of previous theories, the clarity of the theory also means one can easily imagine how to relax assumptions to see if different predictions results. (It is harder to relax assumptions stated in words.)

The analysis starts with the second-stage task-switching decision (assuming attention has been paid to the cue). The current task reward is normalized to 1. Then the agent pays attention when

$$
\phi(\sigma)+\gamma>1
$$

Attentional likelihood increases with the expected reward and decreases with $\lambda$. The math implies that more autistic people are less easily ‘distracted’ and ADHD-like are more easily distracted. We assume $\phi(\sigma)$ is uniformly distributed from $[0,\sigma]$, so $E(\phi(\sigma)=\sigma/2$. 
	
Stage 2: To switch tasks or not? If the cue is attended to, then the probability of switching to task T, denoted $P^{T|A}(\lambda,\sigma)$, is given by this expression: 

$$
P^{T \mid A}(\gamma, \sigma)=\operatorname{Pr}[\phi(\sigma)+\gamma>1 \mid \sigma]=\left\{\begin{array}{cl}
1-\frac{1-\gamma}{\sigma}, & \sigma>1-\gamma \\
0, & \sigma \leq 1-\gamma
\end{array}\right.
$$

The agent switches if salience $\sigma$ is large compared to $1-\lambda$. ASDs are less likely to switch and ADHDs are more likely to switch. 
The value of task-switching, after attending, is the probability of switching times the task value upon switching, $V^{A}(\lambda,\sigma)$,

$$
V^{A}(\gamma, \sigma)=P^{T \mid A}(\gamma, \sigma) \cdot \mathrm{E}[\phi(\sigma)+\gamma-1 \mid \phi(\sigma)+\gamma>1]=\left\{\begin{array}{cl}
\frac{(\sigma-(1-\gamma))^{2}}{2 \sigma}, & \sigma>1-\gamma \\
0, & \sigma \leq 1-\gamma
\end{array}\right.
$$

Second, denotes the (expected) reward of the novel task (i.e. opportunity) associated with the cue, and it can be interpreted as the strength of the reward dopamine signal that is evoked if and when the agent reorients attention to the cue (for further evaluation). 
\end{document}
